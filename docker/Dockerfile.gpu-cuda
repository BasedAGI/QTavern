# Use an NVIDIA CUDA devel image (newer version).
FROM nvidia/cuda:12.2.0-devel-ubuntu22.04

# Disable interactive prompts.
ENV DEBIAN_FRONTEND=noninteractive

# Support a wide range of CUDA architectures.
ENV TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6;8.9;9.0"

# Set CMAKE_GENERATOR to Ninja so that any CMake invocation uses Ninja automatically.
ENV CMAKE_GENERATOR="Ninja"

# -------------------------------------------------------------------------------
# Install system-level dependencies.
# -------------------------------------------------------------------------------
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    curl \
    wget \
    ninja-build \
    python3 \
    python3-pip \
    libssl-dev \
    libffi-dev \
 && rm -rf /var/lib/apt/lists/*

# -------------------------------------------------------------------------------
# Set the working directory.
# -------------------------------------------------------------------------------
WORKDIR /app

# -------------------------------------------------------------------------------
# Create a writable cache directory for Hugging Face and set environment variables.
# -------------------------------------------------------------------------------
RUN mkdir -p /app/.cache && chmod -R 777 /app/.cache
ENV HF_HOME=/app/.cache
ENV HOME=/app

# -------------------------------------------------------------------------------
# Copy only requirements.txt first to leverage Docker cache.
# -------------------------------------------------------------------------------
COPY ./app/requirements.gpu-cuda.txt /app/

# -------------------------------------------------------------------------------
# Force-install torch first so that auto-gptqâ€™s metadata generation finds it.
# -------------------------------------------------------------------------------
RUN python3 -m pip install --upgrade pip==25.0
RUN python3 -m pip install torch==2.6.0

# -------------------------------------------------------------------------------
# Install the the dependencies from requirements.txt.
# -------------------------------------------------------------------------------
RUN python3 -m pip install -r requirements.gpu-cuda.txt

# -------------------------------------------------------------------------------
# Install Git-based dependencies separately.
# -------------------------------------------------------------------------------

# -------------------------------------------------------------------------------
# Install llama_cpp (llama-quantize doesn't seem to be available when installing via pip).
# -------------------------------------------------------------------------------
# Clone the llama.cpp repository.
RUN git clone https://github.com/ggerganov/llama.cpp.git /app/llama_cpp
# Build the binaries.
WORKDIR /app/llama_cpp
RUN mkdir build && cd build && cmake -G Ninja .. && ninja

# -------------------------------------------------------------------------------
# Install AutoAWQ via pip.
# -------------------------------------------------------------------------------
RUN python3 -m pip install -U "git+https://github.com/casper-hansen/AutoAWQ@v0.2.4#egg=AutoAWQ"

# -------------------------------------------------------------------------------
# Install exllamav2.
# -------------------------------------------------------------------------------
RUN git clone https://github.com/turboderp-org/exllamav2.git /app/exllamav2
RUN cd /app/exllamav2 && python3 -m pip install -e .

# -------------------------------------------------------------------------------
# Now copy the rest of the project files.
# -------------------------------------------------------------------------------
COPY ./app /app

# -------------------------------------------------------------------------------
# Reset the working directory to /app.
# -------------------------------------------------------------------------------
WORKDIR /app

# -------------------------------------------------------------------------------
# Expose the Gradio port.
# -------------------------------------------------------------------------------
EXPOSE 7860

# -------------------------------------------------------------------------------
# Set the entrypoint to run your UI.
# -------------------------------------------------------------------------------
CMD ["python3", "app.py"]